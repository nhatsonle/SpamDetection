{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71cbf32c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang đọc dữ liệu...\n",
      "Đang áp dụng tiền xử lý văn bản...\n",
      "Tiền xử lý văn bản hoàn tất.\n",
      "5 dòng đầu với Cleaned_Message:\n",
      "                                             Message  \\\n",
      "0  Go until jurong point, crazy.. Available only ...   \n",
      "1                      Ok lar... Joking wif u oni...   \n",
      "2  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
      "3  U dun say so early hor... U c already then say...   \n",
      "4  Nah I don't think he goes to usf, he lives aro...   \n",
      "\n",
      "                                     Cleaned_Message Category  \n",
      "0  go jurong point crazy available bugis n great ...      ham  \n",
      "1                            ok lar joking wif u oni      ham  \n",
      "2  free entry 2 wkly comp win fa cup final tkts 2...     spam  \n",
      "3                u dun say early hor u c already say      ham  \n",
      "4        nah dont think goes usf lives around though      ham  \n"
     ]
    }
   ],
   "source": [
    "# 6. Triển khai Support Vector Machine (SVM)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import sys\n",
    "import os\n",
    "import joblib \n",
    "module_path = os.path.abspath(os.path.join('..')) \n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "try:\n",
    "    from src.preprocess import clean_text_v1\n",
    "except ImportError:\n",
    "    print(\"Lỗi: Không thể import hàm clean_text_v1 từ src/preprocess.py.\")\n",
    "    print(\"Hãy đảm bảo file tồn tại và chứa hàm cần thiết.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"Lỗi khác khi import hàm tiền xử lý: {e}\")\n",
    "    exit()\n",
    "\n",
    "print(\"Đang đọc dữ liệu...\")\n",
    "try:\n",
    "    data_path = '../data/processed/spam_cleaned_columns.csv'\n",
    "    df = pd.read_csv(data_path, encoding='latin-1')\n",
    "except FileNotFoundError:\n",
    "    print(f\"Lỗi: Không tìm thấy file {data_path}\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "\n",
    "print(\"Đang áp dụng tiền xử lý văn bản...\")\n",
    "df['Cleaned_Message'] = df['Message'].apply(clean_text_v1)\n",
    "print(\"Tiền xử lý văn bản hoàn tất.\")\n",
    "print(\"5 dòng đầu với Cleaned_Message:\")\n",
    "print(df[['Message', 'Cleaned_Message', 'Category']].head())\n",
    "\n",
    "X = df['Cleaned_Message']\n",
    "y = df['Category_Num'] # 0: ham, 1: spam\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9074b0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE # Import SMOTE\n",
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fda349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Đã chia dữ liệu: 4457 huấn luyện, 1115 kiểm tra\n",
      "Đang thực hiện vector hóa TF-IDF...\n",
      "Đang lấy danh sách tên đặc trưng...\n",
      "Số lượng đặc trưng: 5000\n",
      "\n",
      "Kiểm tra các n-grams quan trọng:\n",
      "'limited time' KHÔNG CÓ trong từ điển.\n",
      "'time offer' KHÔNG CÓ trong từ điển.\n",
      "'exclusive discount' KHÔNG CÓ trong từ điển.\n",
      "'50 percent' KHÔNG CÓ trong từ điển.\n",
      "'percent discount' KHÔNG CÓ trong từ điển.\n",
      "'this friday' KHÔNG CÓ trong từ điển.\n",
      "'friday only' KHÔNG CÓ trong từ điển.\n",
      "'limited' KHÔNG CÓ trong từ điển.\n",
      "'offer' CÓ trong từ điển.\n",
      "'exclusive' KHÔNG CÓ trong từ điển.\n",
      "'discount' CÓ trong từ điển.\n",
      "'percent' KHÔNG CÓ trong từ điển.\n",
      "'friday' CÓ trong từ điển.\n",
      "'only' KHÔNG CÓ trong từ điển.\n",
      "\n",
      "Phân bố lớp trước khi áp dụng SMOTE trên tập huấn luyện:\n",
      "Category_Num\n",
      "0    3859\n",
      "1     598\n",
      "Name: count, dtype: int64\n",
      "Đang áp dụng SMOTE trên tập huấn luyện...\n",
      "\n",
      "Phân bố lớp sau khi áp dụng SMOTE trên tập huấn luyện:\n",
      "Category_Num\n",
      "0    3859\n",
      "1    3859\n",
      "Name: count, dtype: int64\n",
      "Kích thước X_train_smote: (7718, 5000)\n",
      "Kích thước ma trận TF-IDF tập huấn luyện: (4457, 5000)\n",
      "Kích thước ma trận TF-IDF tập kiểm tra: (1115, 5000)\n",
      "\n",
      "Bắt đầu huấn luyện mô hình SVM...\n",
      "Đã huấn luyện xong mô hình SVM.\n",
      "\n",
      "Đánh giá mô hình trên tập kiểm thử (sau SMOTE):\n",
      "Confusion Matrix (sau SMOTE):\n",
      "[[958   8]\n",
      " [  9 140]]\n",
      "\n",
      "Classification Report (sau SMOTE):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     HAM (0)       0.99      0.99      0.99       966\n",
      "    SPAM (1)       0.95      0.94      0.94       149\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.97      0.97      0.97      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "#stratify: chia dữ liệu theo tỷ lệ của nhãn\n",
    "#random_state: đảm bảo kết quả chia dữ liệu giống nhau\n",
    "print(f\"\\nĐã chia dữ liệu: {X_train.shape[0]} huấn luyện, {X_test.shape[0]} kiểm tra\")\n",
    "\n",
    "\n",
    "print(\"Đang thực hiện vector hóa TF-IDF...\")\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_features=5000)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train) \n",
    "\n",
    "\n",
    "\n",
    "# print(\"Đang lấy danh sách tên đặc trưng...\")\n",
    "# try:\n",
    "#     feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "#     print(f\"Số lượng đặc trưng: {len(feature_names)}\")\n",
    "    \n",
    "#     print(\"\\nKiểm tra các n-grams quan trọng:\")\n",
    "#     important_ngrams = [\"limited time\", \"time offer\", \"exclusive discount\", \n",
    "#                           \"50 percent\", \"percent discount\", \"this friday\", \"friday only\",\n",
    "#                           \"limited\", \"offer\", \"exclusive\", \"discount\", \"percent\", \"friday\", \"only\"] # Thêm cả unigrams\n",
    "    \n",
    "#     found_ngrams = []\n",
    "#     for ngram in important_ngrams:\n",
    "#         if ngram in feature_names:\n",
    "#             found_ngrams.append(ngram)\n",
    "#             print(f\"'{ngram}' CÓ trong từ điển.\")\n",
    "#         else:\n",
    "#             print(f\"'{ngram}' KHÔNG CÓ trong từ điển.\")\n",
    "    \n",
    "#     if not found_ngrams:\n",
    "#         print(\"Không tìm thấy n-gram quan trọng nào trong từ điển với max_features=5000 và ngram_range=(1,2).\")\n",
    "#         print(\"Hãy thử tăng max_features hoặc sử dụng min_df thay thế.\")\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(f\"Lỗi khi lấy tên đặc trưng: {e}\")\n",
    "\n",
    "\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "\n",
    "print(\"\\nPhân bố lớp trước khi áp dụng SMOTE trên tập huấn luyện:\")\n",
    "print(y_train.value_counts())\n",
    "\n",
    "print(\"Đang áp dụng SMOTE trên tập huấn luyện...\")\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train_tfidf, y_train)\n",
    "\n",
    "print(\"\\nPhân bố lớp sau khi áp dụng SMOTE trên tập huấn luyện:\")\n",
    "print(pd.Series(y_train_smote).value_counts()) # Chuyển y_train_smote sang Series để dùng value_counts()\n",
    "print(f\"Kích thước X_train_smote: {X_train_smote.shape}\")\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Kích thước ma trận TF-IDF tập huấn luyện: {X_train_tfidf.shape}\")\n",
    "print(f\"Kích thước ma trận TF-IDF tập kiểm tra: {X_test_tfidf.shape}\")\n",
    "\n",
    "print(\"\\nBắt đầu huấn luyện mô hình SVM...\")\n",
    "\n",
    "model_svm_smote = SVC(kernel='linear', class_weight='balanced', probability=True, random_state=42)\n",
    "\n",
    "model_svm_smote.fit(X_train_smote, y_train_smote)\n",
    "print(\"Đã huấn luyện xong mô hình SVM.\")\n",
    "\n",
    "   \n",
    "\n",
    "print(\"\\nĐánh giá mô hình trên tập kiểm thử (sau SMOTE):\")\n",
    "    # Nếu dùng GridSearchCV, sử dụng best_svm_smote\n",
    "    # y_pred_smote = best_svm_smote.predict(X_test_tfidf) \n",
    "    \n",
    "    # Nếu huấn luyện trực tiếp\n",
    "y_pred_smote = model_svm_smote.predict(X_test_tfidf)\n",
    "\n",
    "print(\"Confusion Matrix (sau SMOTE):\")\n",
    "print(confusion_matrix(y_test, y_pred_smote))\n",
    "print(\"\\nClassification Report (sau SMOTE):\")\n",
    "print(classification_report(y_test, y_pred_smote, target_names=['HAM (0)', 'SPAM (1)']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e0a1ab09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../results/trained_models/svm_smote_model.pkl']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save model\n",
    "model_path = '../results/trained_models/svm_smote_model.pkl'\n",
    "joblib.dump(model_svm_smote, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00c19188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Đánh giá mô hình trên tập huấn luyện (sau SMOTE):\n",
      "Confusion Matrix (tập huấn luyện):\n",
      "[[3822   37]\n",
      " [ 152 3707]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     HAM (0)       0.96      0.99      0.98      3859\n",
      "    SPAM (1)       0.99      0.96      0.98      3859\n",
      "\n",
      "    accuracy                           0.98      7718\n",
      "   macro avg       0.98      0.98      0.98      7718\n",
      "weighted avg       0.98      0.98      0.98      7718\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_train_pred_smote = cross_val_predict(model_svm_smote, X_train_smote, y_train_smote, cv=5)\n",
    "print(\"\\nĐánh giá mô hình trên tập huấn luyện (sau SMOTE):\")\n",
    "print(\"Confusion Matrix (tập huấn luyện):\")\n",
    "print(confusion_matrix(y_train_smote, y_train_pred_smote))\n",
    "print(classification_report(y_train_smote, y_train_pred_smote, target_names=['HAM (0)', 'SPAM (1)']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "424a4bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Đánh giá mô hình trên tập kiểm thử (sau SMOTE):\n",
      "Confusion Matrix (tập kiểm thử):\n",
      "[[959   7]\n",
      " [ 43 106]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     HAM (0)       0.96      0.99      0.97       966\n",
      "    SPAM (1)       0.94      0.71      0.81       149\n",
      "\n",
      "    accuracy                           0.96      1115\n",
      "   macro avg       0.95      0.85      0.89      1115\n",
      "weighted avg       0.95      0.96      0.95      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = cross_val_predict(model_svm_smote, X_test_tfidf, y_test, cv=5)\n",
    "print(\"\\nĐánh giá mô hình trên tập kiểm thử (sau SMOTE):\")\n",
    "print(\"Confusion Matrix (tập kiểm thử):\")\n",
    "print(confusion_matrix(y_test, y_test_pred))\n",
    "print(classification_report(y_test, y_test_pred, target_names=['HAM (0)', 'SPAM (1)']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5008ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "F1 Score (tập huấn luyện): 0.9751413915559648\n",
      "Precision (tập huấn luyện): 0.9901175213675214\n",
      "Recall (tập huấn luyện): 0.9606115573982897\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "print(\"\\nF1 Score (tập huấn luyện):\", f1_score(y_train_smote, y_train_pred_smote))\n",
    "print(\"Precision (tập huấn luyện):\", precision_score(y_train_smote, y_train_pred_smote))\n",
    "print(\"Recall (tập huấn luyện):\", recall_score(y_train_smote, y_train_pred_smote))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4d3fb7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bắt đầu huấn luyện mô hình SVM không SMOTE...\n",
      "[[3804   55]\n",
      " [  70  528]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     HAM (0)       0.98      0.99      0.98      3859\n",
      "    SPAM (1)       0.91      0.88      0.89       598\n",
      "\n",
      "    accuracy                           0.97      4457\n",
      "   macro avg       0.94      0.93      0.94      4457\n",
      "weighted avg       0.97      0.97      0.97      4457\n",
      "\n",
      "\n",
      "F1 Score (tập huấn luyện): 0.8941574936494496\n",
      "Precision (tập huấn luyện): 0.9056603773584906\n",
      "Recall (tập huấn luyện): 0.882943143812709\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_features=5000)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "print(\"\\nBắt đầu huấn luyện mô hình SVM không SMOTE...\")\n",
    "model_svm = SVC(kernel='linear', class_weight='balanced', probability=True, random_state=42, C=0.1)\n",
    "y_train_pred = cross_val_predict(model_svm, X_train_tfidf, y_train, cv=5)\n",
    "print(confusion_matrix(y_train, y_train_pred))\n",
    "print(classification_report(y_train, y_train_pred, target_names=['HAM (0)', 'SPAM (1)']))\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "print(\"\\nF1 Score (tập huấn luyện):\", f1_score(y_train, y_train_pred))\n",
    "print(\"Precision (tập huấn luyện):\", precision_score(y_train, y_train_pred))\n",
    "print(\"Recall (tập huấn luyện):\", recall_score(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ba7235e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Đánh giá mô hình trên tập kiểm thử (sau SMOTE):\n",
      "Confusion Matrix (tập kiểm thử):\n",
      "[[960   6]\n",
      " [ 42 107]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     HAM (0)       0.96      0.99      0.98       966\n",
      "    SPAM (1)       0.95      0.72      0.82       149\n",
      "\n",
      "    accuracy                           0.96      1115\n",
      "   macro avg       0.95      0.86      0.90      1115\n",
      "weighted avg       0.96      0.96      0.95      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = cross_val_predict(model_svm, X_test_tfidf, y_test, cv=5)\n",
    "print(\"\\nĐánh giá mô hình trên tập kiểm thử (sau SMOTE):\")\n",
    "print(\"Confusion Matrix (tập kiểm thử):\")\n",
    "print(confusion_matrix(y_test, y_test_pred))\n",
    "print(classification_report(y_test, y_test_pred, target_names=['HAM (0)', 'SPAM (1)']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6547d4c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Bắt đầu Test Case ---\n",
      "Số lượng tin nhắn thử nghiệm: 6\n",
      "\n",
      "Tin nhắn sau khi tiền xử lý:\n",
      "1: urgent claim free 1000 prize click httpspamlinkcom\n",
      "2: hey wondering youre free coffee later today\n",
      "3: meet singles area text date 88888 tcs apply 18\n",
      "4: remember buy bread eggs way back\n",
      "5: limited time offer exclusive discount\n",
      "6: 50 percent discount friday\n",
      "\n",
      "Đã vector hóa 6 tin nhắn thành ma trận TF-IDF kích thước: (6, 5000)\n",
      "\n",
      "Đang thực hiện dự đoán bằng mô hình SVM...\n",
      "\n",
      "--- Kết quả Dự đoán Test Case ---\n",
      "\n",
      "Tin nhắn gốc : \"URGENT! Claim your FREE £1000 prize now! Click http://spamlink.com\"\n",
      "  -> Dự đoán   : SPAM\n",
      "  -> Xác suất : [Ham=0.0000, Spam=1.0000]\n",
      "\n",
      "Tin nhắn gốc : \"Hey, wondering if you're free for coffee later today?\"\n",
      "  -> Dự đoán   : HAM\n",
      "  -> Xác suất : [Ham=0.9997, Spam=0.0003]\n",
      "\n",
      "Tin nhắn gốc : \"Meet singles in your area, text DATE to 88888 T&Cs apply 18+\"\n",
      "  -> Dự đoán   : SPAM\n",
      "  -> Xác suất : [Ham=0.0000, Spam=1.0000]\n",
      "\n",
      "Tin nhắn gốc : \"Remember to buy bread and eggs on your way back.\"\n",
      "  -> Dự đoán   : HAM\n",
      "  -> Xác suất : [Ham=0.9998, Spam=0.0002]\n",
      "\n",
      "Tin nhắn gốc : \"Limited time offer! Exclusive discount just for you!\"\n",
      "  -> Dự đoán   : HAM\n",
      "  -> Xác suất : [Ham=0.7141, Spam=0.2859]\n",
      "\n",
      "Tin nhắn gốc : \"50 percent discount this Friday only!\"\n",
      "  -> Dự đoán   : HAM\n",
      "  -> Xác suất : [Ham=0.8768, Spam=0.1232]\n",
      "\n",
      "--- Hoàn thành Test Case ---\n"
     ]
    }
   ],
   "source": [
    "\n",
    "new_messages_for_test = [\n",
    "    \"URGENT! Claim your FREE £1000 prize now! Click http://spamlink.com\", # Tin nhắn có vẻ là SPAM\n",
    "    \"Hey, wondering if you're free for coffee later today?\", # Tin nhắn có vẻ là HAM\n",
    "    \"Meet singles in your area, text DATE to 88888 T&Cs apply 18+\", # Tin nhắn có vẻ là SPAM\n",
    "    \"Remember to buy bread and eggs on your way back.\", # Tin nhắn có vẻ là HAM\n",
    "    \"Limited time offer! Exclusive discount just for you!\", # Tin nhắn có vẻ là SPAM\n",
    "    \"50 percent discount this Friday only!\" #SPAM\n",
    "]\n",
    "\n",
    "print(\"--- Bắt đầu Test Case ---\")\n",
    "print(f\"Số lượng tin nhắn thử nghiệm: {len(new_messages_for_test)}\")\n",
    "\n",
    "try:\n",
    "    cleaned_test_messages = [clean_text_v1(msg) for msg in new_messages_for_test]\n",
    "    print(\"\\nTin nhắn sau khi tiền xử lý:\")\n",
    "    for i, msg in enumerate(cleaned_test_messages):\n",
    "        print(f\"{i+1}: {msg}\")\n",
    "except NameError:\n",
    "    print(\"\\nLỗi: Hàm 'clean_text_v1' chưa được định nghĩa hoặc import.\")\n",
    "    print(\"Vui lòng chạy cell định nghĩa/import hàm này trước.\")\n",
    "    raise\n",
    "\n",
    "\n",
    "try:\n",
    "    new_messages_tfidf_test = tfidf_vectorizer.transform(cleaned_test_messages)\n",
    "    print(f\"\\nĐã vector hóa {len(cleaned_test_messages)} tin nhắn thành ma trận TF-IDF kích thước: {new_messages_tfidf_test.shape}\")\n",
    "except NameError:\n",
    "    print(\"\\nLỗi: Biến 'tfidf_vectorizer' chưa được định nghĩa.\")\n",
    "    print(\"Vui lòng chạy cell huấn luyện TF-IDF Vectorizer trước.\")\n",
    "    raise\n",
    "\n",
    "print(\"\\nĐang thực hiện dự đoán bằng mô hình SVM...\")\n",
    "try:\n",
    "    predictions_test = model_svm_smote.predict(new_messages_tfidf_test)\n",
    "    \n",
    "    probabilities_test = model_svm_smote.predict_proba(new_messages_tfidf_test)\n",
    "except NameError:\n",
    "    print(\"\\nLỗi: Biến 'svm_model' chưa được định nghĩa.\")\n",
    "    print(\"Vui lòng chạy cell huấn luyện mô hình SVM trước.\")\n",
    "    raise\n",
    "except AttributeError:\n",
    "     print(\"\\nLỗi: Không thể lấy xác suất.\")\n",
    "     print(\"Để dùng predict_proba(), mô hình SVM cần được khởi tạo với tham số 'probability=True'.\")\n",
    "     probabilities_test = np.array([[0.5, 0.5]] * len(predictions_test)) \n",
    "\n",
    "# --- 4. Hiển thị kết quả ---\n",
    "print(\"\\n--- Kết quả Dự đoán Test Case ---\")\n",
    "label_map = {0: 'ham', 1: 'spam'} \n",
    "for i, original_message in enumerate(new_messages_for_test):\n",
    "    predicted_label_num = predictions_test[i]\n",
    "    predicted_label_text = label_map[predicted_label_num]\n",
    "    prob_ham = probabilities_test[i][0]\n",
    "    prob_spam = probabilities_test[i][1] \n",
    "\n",
    "    print(f\"\\nTin nhắn gốc : \\\"{original_message}\\\"\")\n",
    "    print(f\"  -> Dự đoán   : {predicted_label_text.upper()}\")\n",
    "    if 'AttributeError' not in locals() or not isinstance(locals()['AttributeError'], AttributeError):\n",
    "         print(f\"  -> Xác suất : [Ham={prob_ham:.4f}, Spam={prob_spam:.4f}]\")\n",
    "\n",
    "print(\"\\n--- Hoàn thành Test Case ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7d23fa",
   "metadata": {},
   "source": [
    "B1:Tạo 1 file google doc -> Note lại toàn bộ kết quả baseline của từng thuật toán (accuracy, precision, recall, f1-score, confusion matrix)\n",
    "B2: Tinh chỉnh siêu tham số\n",
    "- random forest\n",
    "- Logistic Regression\n",
    "B3: Sử dụng GridSearchCV hoặc RandomizedSearchCV (CV: Cross validation)\n",
    "- Cross Validation: K-Fold Cross Validation (Kiểm định chéo K lần)\n",
    "  + Chia dữ liệu: Chia ngẫu nhiên tập train thành K phần, giá trị K thường là 5 hoặc 10\n",
    "  + Lặp K lần: Quá trình huấn luyện và đánh giá dược lặp lại K lần. Trong mỗi lần lặp (ví dụ lần lặp thứ i):\n",
    "    > Chọn Fold kiểm tra: Fold thứ i được giữ lại làm tập dữ liệu kiểm định (validation set) hoặc là \"test fold\" cho lần lặp này.\n",
    "    >Chọn fold huấn luyện: K-1 phần còn lại được gộp lại để làm tập dữ liệu huấn luyện.\n",
    "    >Huấn luyện: Mô hình học máy được huấn luyện trên tập huấn luyện (k-1 folds)\n",
    "    > Đánh giá: Mô hình vừa huấn luyện xong được đánh giá hiệu năng (tính f1-score, accuracy,..) trên tập kiểm định (fold thứ i). Kết quả đánh giá được lưu lại.\n",
    "  + Tổng hợp kết quả: Sau khi thực hiện K lần lặp thì có K kết quả đánh giá. Hiệu năng cuối cùng của mô hình theo phương pháp CV thường được tính bằng lấy trung bình của K kết quả.\n",
    "- GridSearchCV: thử tất cả các tổ hợp\n",
    "- RandomizedSearchCV: thử một số tổ hợp tham số ngẫu nhiên.\n",
    "\n",
    "B4:Cập nhật kết quả: ghi lại chỉ số hiệu năng của mô hình đã tune vào bảng so sánh chung (file google doc ở trên).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbc4cc51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang chạy GridSearchCV trên dữ liệu SMOTE...\n",
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
      "Các tham số SVM tốt nhất sau SMOTE và GridSearchCV: {'C': 10, 'gamma': 1, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import make_scorer, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100], # Có thể thêm hoặc bớt giá trị\n",
    "    'gamma': [0.001, 0.01, 0.1, 1],\n",
    "    'kernel': ['rbf', 'linear'] # Hoặc thêm 'linear' để# Tập trung vào f1_score của lớp SPAM\n",
    "}\n",
    "scorer = make_scorer(f1_score, pos_label=1) # Giả sử 1 là nhãn SPAM nhãn SPAM\n",
    "\n",
    "# Khởi tạo GridSearchCV với SVC (có thể vẫn giữ class_weight='balanced' hoặc bỏ đi để xem SMOTE có đủ không)\n",
    "grid_search_smote = GridSearchCV(SVC(class_weight='balanced', random_state=42), \n",
    "                                    param_grid, \n",
    "                                    cv=5, # Hoặc một giá trị cross-validation khác\n",
    "                                    scoring=scorer, \n",
    "                                    verbose=2, # Để xem tiến trình\n",
    "                                    n_jobs=-1) # Sử dụng tất cả các core nếu có thể\n",
    "\n",
    "print(\"Đang chạy GridSearchCV trên dữ liệu SMOTE...\")\n",
    "grid_search_smote.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "print(\"Các tham số SVM tốt nhất sau SMOTE và GridSearchCV:\", grid_search_smote.best_params_)\n",
    "best_svm_after_smote = grid_search_smote.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5a6f7ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Bắt đầu Test Case ---\n",
      "Số lượng tin nhắn thử nghiệm: 6\n",
      "\n",
      "Tin nhắn sau khi tiền xử lý:\n",
      "1: urgent claim free 1000 prize click httpspamlinkcom\n",
      "2: hey wondering youre free coffee later today\n",
      "3: meet singles area text date 88888 tcs apply 18\n",
      "4: remember buy bread eggs way back\n",
      "5: limited time offer exclusive discount\n",
      "6: 50 percent discount friday\n",
      "\n",
      "Đã vector hóa 6 tin nhắn thành ma trận TF-IDF kích thước: (6, 5000)\n",
      "\n",
      "Đang thực hiện dự đoán bằng mô hình SVM...\n",
      "\n",
      "Lỗi: Không thể lấy xác suất.\n",
      "Để dùng predict_proba(), mô hình SVM cần được khởi tạo với tham số 'probability=True'.\n",
      "\n",
      "--- Kết quả Dự đoán Test Case ---\n",
      "\n",
      "Tin nhắn gốc : \"URGENT! Claim your FREE £1000 prize now! Click http://spamlink.com\"\n",
      "  -> Dự đoán   : SPAM\n",
      "  -> Xác suất : [Ham=0.5000, Spam=0.5000]\n",
      "\n",
      "Tin nhắn gốc : \"Hey, wondering if you're free for coffee later today?\"\n",
      "  -> Dự đoán   : HAM\n",
      "  -> Xác suất : [Ham=0.5000, Spam=0.5000]\n",
      "\n",
      "Tin nhắn gốc : \"Meet singles in your area, text DATE to 88888 T&Cs apply 18+\"\n",
      "  -> Dự đoán   : SPAM\n",
      "  -> Xác suất : [Ham=0.5000, Spam=0.5000]\n",
      "\n",
      "Tin nhắn gốc : \"Remember to buy bread and eggs on your way back.\"\n",
      "  -> Dự đoán   : HAM\n",
      "  -> Xác suất : [Ham=0.5000, Spam=0.5000]\n",
      "\n",
      "Tin nhắn gốc : \"Limited time offer! Exclusive discount just for you!\"\n",
      "  -> Dự đoán   : HAM\n",
      "  -> Xác suất : [Ham=0.5000, Spam=0.5000]\n",
      "\n",
      "Tin nhắn gốc : \"50 percent discount this Friday only!\"\n",
      "  -> Dự đoán   : HAM\n",
      "  -> Xác suất : [Ham=0.5000, Spam=0.5000]\n",
      "\n",
      "--- Hoàn thành Test Case ---\n"
     ]
    }
   ],
   "source": [
    "\n",
    "new_messages_for_test = [\n",
    "    \"URGENT! Claim your FREE £1000 prize now! Click http://spamlink.com\", # Tin nhắn có vẻ là SPAM\n",
    "    \"Hey, wondering if you're free for coffee later today?\", # Tin nhắn có vẻ là HAM\n",
    "    \"Meet singles in your area, text DATE to 88888 T&Cs apply 18+\", # Tin nhắn có vẻ là SPAM\n",
    "    \"Remember to buy bread and eggs on your way back.\", # Tin nhắn có vẻ là HAM\n",
    "    \"Limited time offer! Exclusive discount just for you!\", # Tin nhắn có vẻ là SPAM\n",
    "    \"50 percent discount this Friday only!\"\n",
    "]\n",
    "\n",
    "print(\"--- Bắt đầu Test Case ---\")\n",
    "print(f\"Số lượng tin nhắn thử nghiệm: {len(new_messages_for_test)}\")\n",
    "\n",
    "# --- 1. Tiền xử lý các tin nhắn mới ---\n",
    "# Áp dụng hàm tiền xử lý đã có (cần đảm bảo hàm clean_text_v1 đã được định nghĩa/import ở cell trước)\n",
    "try:\n",
    "    cleaned_test_messages = [clean_text_v1(msg) for msg in new_messages_for_test]\n",
    "    print(\"\\nTin nhắn sau khi tiền xử lý:\")\n",
    "    for i, msg in enumerate(cleaned_test_messages):\n",
    "        print(f\"{i+1}: {msg}\")\n",
    "except NameError:\n",
    "    print(\"\\nLỗi: Hàm 'clean_text_v1' chưa được định nghĩa hoặc import.\")\n",
    "    print(\"Vui lòng chạy cell định nghĩa/import hàm này trước.\")\n",
    "    # Dừng thực thi cell này nếu hàm chưa có\n",
    "    raise\n",
    "\n",
    "# --- 2. Vector hóa các tin nhắn mới ---\n",
    "# *** Quan trọng: Dùng đối tượng tfidf_vectorizer đã fit từ cell trước, chỉ gọi .transform() ***\n",
    "try:\n",
    "    new_messages_tfidf_test = tfidf_vectorizer.transform(cleaned_test_messages)\n",
    "    print(f\"\\nĐã vector hóa {len(cleaned_test_messages)} tin nhắn thành ma trận TF-IDF kích thước: {new_messages_tfidf_test.shape}\")\n",
    "except NameError:\n",
    "    print(\"\\nLỗi: Biến 'tfidf_vectorizer' chưa được định nghĩa.\")\n",
    "    print(\"Vui lòng chạy cell huấn luyện TF-IDF Vectorizer trước.\")\n",
    "    raise\n",
    "\n",
    "# --- 3. Dự đoán ---\n",
    "print(\"\\nĐang thực hiện dự đoán bằng mô hình SVM...\")\n",
    "try:\n",
    "    # Dự đoán nhãn (0 hoặc 1)\n",
    "    predictions_test = best_svm_after_smote.predict(new_messages_tfidf_test)\n",
    "    # Dự đoán xác suất (P(ham), P(spam))\n",
    "    # Lưu ý: svm_model phải được khởi tạo với probability=True ở cell huấn luyện\n",
    "    probabilities_test = best_svm_after_smote.predict_proba(new_messages_tfidf_test)\n",
    "except NameError:\n",
    "    print(\"\\nLỗi: Biến 'svm_model' chưa được định nghĩa.\")\n",
    "    print(\"Vui lòng chạy cell huấn luyện mô hình SVM trước.\")\n",
    "    raise\n",
    "except AttributeError:\n",
    "     print(\"\\nLỗi: Không thể lấy xác suất.\")\n",
    "     print(\"Để dùng predict_proba(), mô hình SVM cần được khởi tạo với tham số 'probability=True'.\")\n",
    "     # Gán giá trị mặc định để code không bị lỗi tiếp\n",
    "     probabilities_test = np.array([[0.5, 0.5]] * len(predictions_test)) # Tạo mảng xác suất giả định\n",
    "\n",
    "# --- 4. Hiển thị kết quả ---\n",
    "print(\"\\n--- Kết quả Dự đoán Test Case ---\")\n",
    "label_map = {0: 'ham', 1: 'spam'} # Ánh xạ nhãn số về chữ\n",
    "\n",
    "for i, original_message in enumerate(new_messages_for_test):\n",
    "    predicted_label_num = predictions_test[i]\n",
    "    predicted_label_text = label_map[predicted_label_num]\n",
    "    prob_ham = probabilities_test[i][0] # Xác suất là ham (lớp 0)\n",
    "    prob_spam = probabilities_test[i][1] # Xác suất là spam (lớp 1)\n",
    "\n",
    "    print(f\"\\nTin nhắn gốc : \\\"{original_message}\\\"\")\n",
    "    # print(f\"Tin nhắn sạch: \\\"{cleaned_test_messages[i]}\\\"\") # Bỏ comment nếu muốn xem\n",
    "    print(f\"  -> Dự đoán   : {predicted_label_text.upper()}\")\n",
    "    # Chỉ in xác suất nếu lấy được\n",
    "    if 'AttributeError' not in locals() or not isinstance(locals()['AttributeError'], AttributeError):\n",
    "         print(f\"  -> Xác suất : [Ham={prob_ham:.4f}, Spam={prob_spam:.4f}]\")\n",
    "\n",
    "print(\"\\n--- Hoàn thành Test Case ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6987eb33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Đánh giá mô hình trên tập kiểm thử (đã SMOTE):\n",
      "Confusion Matrix (sau SMOTE):\n",
      "[[945  21]\n",
      " [ 17 132]]\n",
      "\n",
      "Classification Report (sau SMOTE):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     HAM (0)       0.98      0.98      0.98       966\n",
      "    SPAM (1)       0.86      0.89      0.87       149\n",
      "\n",
      "    accuracy                           0.97      1115\n",
      "   macro avg       0.92      0.93      0.93      1115\n",
      "weighted avg       0.97      0.97      0.97      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nĐánh giá mô hình trên tập kiểm thử (đã SMOTE):\")\n",
    "    # Nếu dùng GridSearchCV, sử dụng best_svm_smote\n",
    "    # y_pred_smote = best_svm_smote.predict(X_test_tfidf) \n",
    "    \n",
    "    # Nếu huấn luyện trực tiếp\n",
    "y_pred_smote = best_svm_after_smote.predict(X_test_tfidf)\n",
    "\n",
    "print(\"Confusion Matrix (sau SMOTE):\")\n",
    "print(confusion_matrix(y_test, y_pred_smote))\n",
    "print(\"\\nClassification Report (sau SMOTE):\")\n",
    "print(classification_report(y_test, y_pred_smote, target_names=['HAM (0)', 'SPAM (1)']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95ea76f",
   "metadata": {},
   "source": [
    "Trong NLP, có rất nhiều cách để vector hoá 1 văn bản text thành ma trận dạng số: Bag_of_words, TF-IDF, word embeddings,..\n",
    "- Bag_of_words: \"I arrive home at 6 o'clock\" => [1,1,1,1]\n",
    "\"I come back home and then I go to my grandpa's house\" \n",
    "- TF-IDF: Term Frequency-Inverse Document Frequency\n",
    "Term Frequency (Bag_of_words) * Inverse Document Frequency \n",
    "IDF = log(number of documents / number of documents in which this word exists)\n",
    "\n",
    "VD: 'Tôi đi học'\n",
    "'Tôi đi chơi'\n",
    "'Mua đồ ăn'\n",
    "\n",
    "IDF = log(3 / 2) = 0.58 \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
